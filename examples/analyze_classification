#!/usr/bin/env python

"""
Analyzes gesture data by running different combinations of sessions for
training and testing classifiers.

There are three primary ways to analyze data. The simplest is to build a single
classifier by specifying the session IDs for training and testing separately.

Another way is to specify a single list of sessions and build a set of
classifiers based on a leave-p-out scheme. Here, every combination of
train/test pairs is generated, a classifier is built and tested for each, and
the result is averaged.

Finally, the most flexible way to analyze the data is to write a JSON file
describing all of the desired classifiers to create. Both single and
leave-p-out classifiers can be built with this method, as well as arbitrary
groups of classifiers that should be averaged. The last case can be useful if,
for instance, you have a limited test data set that you want to train for using
several different training sets and an average is desired.
"""

import os
import sys
import json
import argparse

try:
    import cPickle as pickle
except ImportError:
    import pickle

try:
    from pygesture import config
except:
    sys.path.insert(0, '..')
    from pygesture import config

from pygesture import filestruct
from pygesture.analysis import classification


def main(parser):
    args = parser.parse_args()
    cfg = config.Config(args.config)

    if args.rootdir:
        rootdir = os.path.normpath(args.rootdir)
    else:
        rootdir = cfg.data_path

    labels = {g.label: (g.name, g.description) for g in cfg.gestures}
    if args.labels:
        try:
            labels = {int(k): labels[int(k)] for k in args.labels.split(',')}
        except KeyError:
            parser.error("Labels specified weren't found.")

    if not args.pids:
        parser.error("Must provide at least one particpant ID with -p flat")

    if args.pids == ['all']:
        pids = filestruct.get_participant_list(rootdir)
    else:
        pids = args.pids

    if args.jsonfile:
        json_data = json.load(open(args.jsonfile))

        cv_groups = json_data['cv_groups']
        avg_groups = json_data['avg_groups']
        single_clfs = json_data['single_clfs']

        cm_list = []

        for cv_group in cv_groups:
            cm = classification.run_cv(
                rootdir, pids, cv_group,
                label_dict=labels)
            cm_list.append(cm)

        for avg_group in avg_groups:
            cm = classification.run_avg(
                rootdir, pids, avg_group,
                label_dict=labels)
            cm_list.append(cm)

        for single_clf in single_clfs:
            cm = classification.run_single(
                rootdir, pids, single_clf,
                label_dict=labels)
            cm_list.append(cm)

        if args.outfile:
            pickle.dump(cm_list, open(args.outfile, 'wb'))

        if args.show:
            for cm in cm_list:
                cm.print_avg()

    elif args.lpo:
        n_train, sid_list = args.lpo
        cv_group = {
            'name': args.name,
            'n_train': int(n_train),
            'sid_list': sid_list.split(',')
        }
        cm = classification.run_cv(
            rootdir, pids, cv_group,
            label_dict=labels)

        if args.show:
            cm.print_avg()

    elif args.ids:
        sid_list_train, sid_list_test = args.ids
        single_clf = {
            'name': args.name,
            'sid_list_train': sid_list_train.split(','),
            'sid_list_test': sid_list_test.split(',')
        }

        cm = classification.run_single(
            rootdir, pids, single_clf,
            label_dict=labels)

        if args.show:
            cm.print_avg()

    else:
        parser.error("Must use one option: -i, -j, or -p")


def parse_args():
    parser = argparse.ArgumentParser(
        description="Run a classifier on single participant data.")
    parser.add_argument(
        '-r', '--rootdir',
        help="Root data directory. Defaults to the path in the config.")
    parser.add_argument(
        '-p', '--pids',
        dest='pids',
        nargs='+',
        help="Participant identifier(s) (or 'all' to process all pids).")
    parser.add_argument(
        '-i', '--ids',
        dest='ids',
        nargs=2,
        help="Participant ID, training IDs, and testing IDs.")
    parser.add_argument(
        '-j', '--json',
        dest='jsonfile',
        action='store',
        help="Batch process classifiers according to input JSON file.")
    parser.add_argument(
        '--lpo',
        dest='lpo',
        action='store',
        nargs=2,
        help="Run leave-p-out with n_train first, then sid list.")
    parser.add_argument(
        '-s', '--savepath',
        dest='savepath',
        action='store',
        help="Save generated plots to the specified path.")
    parser.add_argument(
        '-n', '--name',
        dest='name',
        action='store',
        default='LDA',
        help="Name of the classifier (used with -i option).")
    parser.add_argument(
        '-o', '--output',
        dest='outfile',
        action='store',
        help="Specify a file to save confusion matrices to.")
    parser.add_argument(
        '-w', '--show',
        dest='show',
        action='store_true',
        default=True,
        help="Show confusion matrices that are generated.")
    parser.add_argument(
        '-c', '--config',
        dest='config',
        default='config.py',
        help="Config file. Default is `config.py` (current directory).")
    parser.add_argument(
        '-l', '--labels',
        help="Comma-separated list of labels to include. All by default.")

    return parser


if __name__ == '__main__':
    main(parse_args())
